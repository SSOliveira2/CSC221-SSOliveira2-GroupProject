{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "241c3700-3d0a-452b-b7c9-726f799fcfe4",
   "metadata": {},
   "source": [
    "# Group Project: Web Scraping List of U.S. States by Population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52422dc2-c2f7-4291-8bd3-d381b2b50fbd",
   "metadata": {},
   "source": [
    "### Author: <font color='red'> Stella Olveira </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a512afdd-5595-4665-b282-6a082ca376e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "993cba8d-7d3f-48d1-8711-d12b9901684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b919f855-8686-4a20-b7f6-8202097671ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/List_of_U.S._states_and_territories_by_population\"\n",
    "\n",
    "# User-Agent to avoid blocking\n",
    "headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "# Make request\n",
    "req = Request(url, headers=headers)\n",
    "page = urlopen(req).read()\n",
    "\n",
    "# Parse HTML with BeautifulSoup\n",
    "soup = BeautifulSoup(page, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91e8e5b9-909e-48a1-a52b-69f6da96a106",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find(\"table\", {\"class\": \"wikitable\"})\n",
    "# Extract table headers\n",
    "headers = []\n",
    "for th in table.find_all(\"th\"):\n",
    "    headers.append(th.text.strip())\n",
    "# Extract all rows\n",
    "rows = []\n",
    "for tr in table.find_all(\"tr\")[1:]:  # skip header row\n",
    "    cells = tr.find_all([\"td\", \"th\"])\n",
    "    row = [cell.text.strip() for cell in cells]\n",
    "    if row:\n",
    "        rows.append(row)\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50831ddf-a8a7-4ba0-87c3-3dfe65ae6d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIRST 10 ROWS OF SCRAPED DATA:\n",
      "\n",
      "                    0              1           2       3          4   5   \\\n",
      "0  July 1, 2024 (est.)  April 1, 2020           %    Abs.      Seats   %   \n",
      "1           California     39,431,263  39,538,223   6.13%  2,284,267  52   \n",
      "2                Texas     31,290,831  29,145,505  15.91%  3,999,944  38   \n",
      "3              Florida     23,372,215  21,538,187  14.56%  2,736,877  28   \n",
      "4             New York     19,867,248  20,201,249   4.25%    823,147  26   \n",
      "5         Pennsylvania     13,078,751  13,002,700   2.36%    300,321  17   \n",
      "6             Illinois     12,710,158  12,812,508  −0.14%    −18,124  17   \n",
      "7                 Ohio     11,883,304  11,799,448   2.28%    262,944  15   \n",
      "8              Georgia     11,180,878  10,711,908  10.57%  1,024,255  14   \n",
      "9       North Carolina     11,046,024  10,439,388   9.48%    903,905  14   \n",
      "\n",
      "       6        7        8        9       10  \n",
      "0    None     None     None     None    None  \n",
      "1  11.95%  732,189  760,350  11.800%  10.04%  \n",
      "2   8.74%  728,638  766,987   8.698%   7.43%  \n",
      "3   6.44%  717,940  769,221   6.428%   5.58%  \n",
      "4   5.98%  721,473  776,971   6.029%   5.20%  \n",
      "5   3.91%  684,353  764,865   3.881%   3.53%  \n",
      "6   3.91%  674,343  753,677   3.824%   3.53%  \n",
      "7   3.45%  694,085  786,630   3.521%   3.16%  \n",
      "8   3.22%  669,494  765,136   3.197%   2.97%  \n",
      "9   3.22%  652,462  745,671   3.116%   2.97%  \n"
     ]
    }
   ],
   "source": [
    "print(\"FIRST 10 ROWS OF SCRAPED DATA:\\n\")\n",
    "print(df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "533ff602-40a2-47db-82d0-926b40f908f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CSV saved as 'CSC221-webscrape-data.csv'\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"CSC221-webscrape-data.csv\", index=False)\n",
    "print(\"\\nCSV saved as 'CSC221-webscrape-data.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0974ad1d-f5a7-4f7f-853a-5c87b03da482",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
